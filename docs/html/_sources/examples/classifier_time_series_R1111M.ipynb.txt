{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 71,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "import sys\n",
    "\n",
    "# sys.path.append('/Users/m/PTSA_NEW_GIT/')\n",
    "import numpy as np\n",
    "from numpy.testing import *\n",
    "from ptsa.data.readers import BaseEventReader\n",
    "from ptsa.data.filters.MorletWaveletFilter import MorletWaveletFilter\n",
    "from ptsa.data.readers.TalReader import TalReader\n",
    "from ptsa.data.readers import EEGReader\n",
    "from ptsa.data.filters import MonopolarToBipolarMapper\n",
    "from ptsa.data.filters import DataChopper\n",
    "from ptsa.data.common import xr\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.metrics import roc_auc_score, roc_curve\n",
    "from scipy.stats.mstats import zscore\n",
    "import numpy.testing as npt\n",
    "import cPickle\n",
    "import os\n",
    "from collections import namedtuple\n",
    "from time import time"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "%matplotlib inline\n",
    "\n",
    "import matplotlib\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "When runing first time set compute_classifier_flag to True. Subsequent runc can be executed with flag set to False because classifier will be computed and stored on the hard drive at that time"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "subject = 'R1111M'\n",
    "e_path = os.path.join('/Users/m/data/events/RAM_FR1/',subject+'_events.mat')\n",
    "                      \n",
    "tal_path = os.path.join('/Users/m/data/eeg',subject,'tal',subject+'_talLocs_database_bipol.mat')\n",
    "\n",
    "ClassifierData = namedtuple('ClassifierData', ['lr_classifier', 'mean','std'])\n",
    "\n",
    "compute_classifier_flag = False"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "reading electrodes information"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def get_monopolar_and_bipolar_electrodes():\n",
    "    tal_reader = TalReader(filename=tal_path)\n",
    "    monopolar_channels = tal_reader.get_monopolar_channels()\n",
    "    bipolar_pairs = tal_reader.get_bipolar_pairs()\n",
    "    return monopolar_channels, bipolar_pairs"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "reading events"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def get_events():\n",
    "    # ---------------- NEW STYLE PTSA -------------------\n",
    "    base_e_reader = BaseEventReader(filename=e_path, eliminate_events_with_no_eeg=True)\n",
    "\n",
    "    base_events = base_e_reader.read()\n",
    "\n",
    "    base_events = base_events[base_events.type == 'WORD']\n",
    "    return base_events"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def get_bp_data(base_events):\n",
    "    # retaining first session\n",
    "    sessions = np.unique(base_events.session)\n",
    "    # dataroot = base_events[0].eegfile\n",
    "    # base_events = base_events[base_events.eegfile == dataroot]\n",
    "\n",
    "    eeg_reader = EEGReader(events=base_events, channels=monopolar_channels,\n",
    "                           start_time=0.0, end_time=1.6, buffer_time=1.0)\n",
    "\n",
    "    base_eegs = eeg_reader.read()\n",
    "\n",
    "    m2b = MonopolarToBipolarMapper(time_series=base_eegs, bipolar_pairs=bipolar_pairs)\n",
    "    bp_eegs = m2b.filter()\n",
    "    return bp_eegs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def compute_wavelets(base_events):\n",
    "    from time import time\n",
    "    s = time()\n",
    "\n",
    "    bp_eegs = get_bp_data(base_events)\n",
    "    wf = MorletWaveletFilter(time_series=bp_eegs,\n",
    "                             freqs=np.logspace(np.log10(3), np.log10(180), 8),\n",
    "                             output='power',\n",
    "                             frequency_dim_pos=0,\n",
    "                             verbose=True\n",
    "                             )\n",
    "    pow_wavelet, phase_wavelet = wf.filter()\n",
    "    print 'TOTAL WAVELET TIME=', time() - s\n",
    "    return pow_wavelet"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def prepare_classifier_data(zscore_mean_powers,evs,sess_min,sess_max):\n",
    "    session_mask = (evs.session >= sess_min) & (evs.session <= sess_max)\n",
    "    evs_sel = evs[session_mask]\n",
    "    recalls = evs_sel.recalled.astype(np.int)\n",
    "    features = zscore_mean_powers[session_mask, ...]\n",
    "    \n",
    "    return features, recalls"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def train_classifier(features, recalls):\n",
    "    \n",
    "    lr_classifier = LogisticRegression(C=7.2e-4, penalty='l2', class_weight='auto', solver='liblinear')\n",
    "    lr_classifier.fit(features, recalls)\n",
    "    return lr_classifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def compute_continuous_wavelets(session=0):\n",
    "    dataroot = base_events[base_events.session==session][0].eegfile\n",
    "    session_reader = EEGReader(session_dataroot=dataroot, channels=monopolar_channels)\n",
    "    session_eegs = session_reader.read()\n",
    "\n",
    "    m2b = MonopolarToBipolarMapper(time_series=session_eegs, bipolar_pairs=bipolar_pairs)\n",
    "    session_bp_eegs = m2b.filter()\n",
    "\n",
    "    wf = MorletWaveletFilter(time_series=session_bp_eegs,\n",
    "                         freqs=np.logspace(np.log10(3), np.log10(180), 8),\n",
    "                         output='power',\n",
    "                         frequency_dim_pos=0,\n",
    "                         verbose=True\n",
    "                         )\n",
    "    \n",
    "    pow_wavelet_session, phase_wavelet_session = wf.filter()\n",
    "    return pow_wavelet_session"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This function chops continuous time series into chunks corresponding to events where events can in fact be specified using simple array of offsets. Offsets then correspond to positions at which time series will be cut - note that you may cut eeg series but also time series of wavelets cooeficients"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def chop_time_series(time_series,start_offsets):\n",
    "    dc = DataChopper(start_offsets=start_offsets, session_data=time_series, start_time=0.0, end_time=1.6)\n",
    "    chopped_time_series = dc.filter()\n",
    "    return chopped_time_series"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def compute_classifier_features(pow_wavelet):\n",
    "    np.log10(pow_wavelet.data, out=pow_wavelet.data);\n",
    "\n",
    "    pow_wavelet = pow_wavelet.transpose('events', \"bipolar_pairs\", \"frequency\", \"time\")\n",
    "\n",
    "    mean_powers_nd = np.nanmean(pow_wavelet.data, axis=-1)\n",
    "\n",
    "    mean_powers_rs = mean_powers_nd.reshape(mean_powers_nd.shape[0], -1)\n",
    "    mean_powers_rs.shape\n",
    "\n",
    "    zscore_mean_powers = zscore(mean_powers_rs, axis=0, ddof=1)\n",
    "    \n",
    "    return zscore_mean_powers"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This function computes zscoring params - instead of using zscore function we will use more pedestrian way of zscoring"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def compute_zscoring_params(log_pow_wavelet):\n",
    "    transposed_log_pow_wavelet = log_pow_wavelet.transpose('events', \"bipolar_pairs\", \"frequency\", \"time\")\n",
    "    mean_powers_nd = np.nanmean(transposed_log_pow_wavelet.data, axis=-1)\n",
    "    mean_powers_rs = mean_powers_nd.reshape(mean_powers_nd.shape[0], -1)\n",
    "    m = np.mean(mean_powers_rs,axis=0)\n",
    "#     print m[:3]\n",
    "    s = np.std(mean_powers_rs,axis=0,ddof=1)\n",
    "    \n",
    "    zscore_mean_powers = zscore(mean_powers_rs, axis=0, ddof=1)\n",
    "    \n",
    "    z_score = (mean_powers_rs-m)/s\n",
    "    npt.assert_array_equal(zscore_mean_powers,z_score)\n",
    "    return m,s"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "this function zscores features using mean and std dev returned by compute_zscoring_params"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def compute_features_using_zscoring_params(pow_wavelet,mean,std):\n",
    "    log_pow_wavelet = np.log10(pow_wavelet.data);\n",
    "\n",
    "    transposed_log_pow_wavelet = pow_wavelet.transpose('events', \"bipolar_pairs\", \"frequency\", \"time\")\n",
    "\n",
    "    mean_powers_nd = np.nanmean(transposed_log_pow_wavelet.data, axis=-1)\n",
    "\n",
    "    mean_powers_rs = mean_powers_nd.reshape(mean_powers_nd.shape[0], -1)\n",
    "    mean_powers_rs.shape\n",
    "    \n",
    "    z_score_mean_powers = (mean_powers_rs-mean)/std\n",
    "    \n",
    "    return z_score_mean_powers"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "this is just a test function not used in \"production code\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def test_zscoring_computations():\n",
    "    s=time()\n",
    "    pow_wavelet = compute_wavelets(base_events)\n",
    "    print 'TIME: EEG READING + WAVELETS=',time()-s\n",
    "    zscore_mean_powers = compute_classifier_features(pow_wavelet)\n",
    "    mean,std = compute_zscoring_params(log_pow_wavelet=pow_wavelet)\n",
    "    transposed_log_pow_wavelet =pow_wavelet.transpose('events', \"bipolar_pairs\", \"frequency\", \"time\")\n",
    "    mean_powers_nd = np.nanmean(transposed_log_pow_wavelet.data, axis=-1)\n",
    "    mean_powers_rs = mean_powers_nd.reshape(mean_powers_nd.shape[0], -1)\n",
    "    print zscore_mean_powers - (mean_powers_rs-mean)/std\n",
    "    zscore_mean_powers_alt = compute_features_using_zscoring_params(pow_wavelet,mean,std)\n",
    "    zscore_mean_powers_alt-zscore_mean_powers"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This function computes classifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 86,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "def compute_classifier():\n",
    "    s=time()\n",
    "    pow_wavelet = compute_wavelets(base_events)\n",
    "    print 'TIME: EEG READING + WAVELETS=',time()-s\n",
    "    pow_wavelet = pow_wavelet.remove_buffer(duration=1.0)\n",
    "    \n",
    "    np.log10(pow_wavelet.data, out=pow_wavelet.data);\n",
    "    log_pow_wavelet = pow_wavelet\n",
    "    mean,std = compute_zscoring_params(log_pow_wavelet=log_pow_wavelet)\n",
    "    zscore_mean_powers = compute_features_using_zscoring_params(log_pow_wavelet,mean,std)\n",
    "    \n",
    "#     zscore_mean_powers = compute_classifier_features(pow_wavelet)\n",
    "    training_features, training_recalls  = prepare_classifier_data(zscore_mean_powers, base_events,sess_min=0,sess_max=1)\n",
    "    lr_classifier = train_classifier(training_features,training_recalls)\n",
    "\n",
    "    validation_features, validation_recalls  = prepare_classifier_data(zscore_mean_powers, base_events,sess_min=2,sess_max=2)\n",
    "    \n",
    "    recall_prob_array = lr_classifier.predict_proba(training_features)[:, 1]\n",
    "    auc = roc_auc_score(training_recalls, recall_prob_array)\n",
    "    print 'auc=', auc\n",
    "    \n",
    "    validation_recall_prob_array = lr_classifier.predict_proba(validation_features)[:, 1]\n",
    "    auc = roc_auc_score(validation_recalls, validation_recall_prob_array)\n",
    "    print 'auc=', auc            \n",
    "    classifier_data = ClassifierData(lr_classifier=lr_classifier,mean=mean,std=std)\n",
    "\n",
    "    # save the classifier\n",
    "    with open('classifier_data_'+subject+'.pkl', 'wb') as fid:\n",
    "        cPickle.dump(classifier_data, fid)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This function will tak as an input the following:\n",
    "1. wavelets computed for the entire session\n",
    "2. ClassifierData tuple - containing trained classifier, mean and std dev for z scoring\n",
    "3. start_time (in seconds) - determines the time location of the epoch at which we being computting probs tgime series\n",
    "4. end_time (in seconds) - determines the last epoch of thr probs time series\n",
    "5. resolution - separation of the time points (in seconds) at which we calculate recall probabilities\n",
    "5. slice_size - determines  the number of choping operations DataChopper performs  - since Data Chopper returns eeg time series using smaller slice_size has less strain on memory. in principle call Data Chopper only once but if the number of chops is large we might run out of memory..."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 87,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def compute_probs_ts(pow_wavelet_session,classifier_data,start_time = 10.0, end_time=20.0, slice_size=10, resolution=0.1):\n",
    "    \n",
    "    lr_classifier = classifier_data.lr_classifier\n",
    "    mean = classifier_data.mean\n",
    "    std = classifier_data.std\n",
    "    \n",
    "    #resolution is in seconds\n",
    "    samplerate = float(pow_wavelet_session['samplerate'])\n",
    "    \n",
    "    number_of_samples_in_resolution = int(round(resolution*samplerate))\n",
    "    \n",
    "    total_number_of_items  = int(round((end_time-start_time)/resolution))\n",
    "                          \n",
    "    number_of_compute_iterations = total_number_of_items / slice_size\n",
    "\n",
    "    probs_list=[]\n",
    "    \n",
    "\n",
    "    for n in xrange(number_of_compute_iterations):\n",
    "        st = start_time + n*slice_size*resolution\n",
    "        initial_offset = int(round(st*samplerate))\n",
    "        start_offsets = initial_offset +  np.arange(slice_size)*number_of_samples_in_resolution\n",
    "        \n",
    "        pow_wavelet_chopped = chop_time_series(time_series=pow_wavelet_session,start_offsets=start_offsets)\n",
    "        pow_wavelet_chopped = pow_wavelet_chopped.rename({'start_offsets':'events'})\n",
    "        np.log10(pow_wavelet_chopped.data, out=pow_wavelet_chopped.data) \n",
    "        \n",
    "        features = compute_features_using_zscoring_params(pow_wavelet_chopped,mean,std)    \n",
    "        probs = lr_classifier.predict_proba(features)[:, 1]\n",
    "                \n",
    "        probs_list.append(probs)\n",
    "    \n",
    "    \n",
    "    probs_array = np.hstack(probs_list)\n",
    "    time_axis = start_time + np.arange(probs_array.shape[0])*resolution\n",
    "    return time_axis, probs_array"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Begining of the computational pipeline that computes classifiers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 88,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "base_events = get_events()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 89,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "monopolar_channels, bipolar_pairs = get_monopolar_and_bipolar_electrodes()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "if compute_classifier_flag:\n",
    "    compute_classifier()\n",
    "\n",
    "#we read classifier from the disk    \n",
    "    \n",
    "with open('classifier_data_'+subject+'.pkl', 'rb') as fid:\n",
    "    classifier_data = cPickle.load(fid)\n",
    "\n",
    "lr_classifier = classifier_data.lr_classifier\n",
    "mean = classifier_data.mean\n",
    "std = classifier_data.std"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Computing wavelets for entire session (continuous mode)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "pow_wavelet_session = compute_continuous_wavelets(session=0)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Here we are computing time series of recall probabilities"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "time_axis, probs_array = compute_probs_ts(pow_wavelet_session,\n",
    "                                          classifier_data,\n",
    "                                          start_time=50.0, \n",
    "                                          end_time=70.0, \n",
    "                                          slice_size=10, \n",
    "                                          resolution=0.1\n",
    "                                          )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "plt.plot(time_axis,probs_array)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    ""
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2.0
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}